model_list:
  - model_name: unified-endpoint  # Your single endpoint name
    litellm_params:
      model: openai/gpt-4.1-nano  # OpenAI model
      api_key: os.environ/OPENAI_API_KEY
      rpm: 3  # 10 requests/minute for OpenAI

  # - model_name: unified-endpoint  # Same endpoint name
  #   litellm_params:
  #     model: ollama/llama3.2  # Ollama model
  #     api_base: http://localhost:11434  # Ollama server
  #     rpm: 20

# router_settings:
#   routing_strategy: "simple-shuffle"  # Added recommended router setting
